- [[What Is ChatGPT Doing...and Why Does It Work? (highlights)]]
  collapsed:: true
	- [[Summary]]
		- It’s Just Adding One Word at a Time
		  collapsed:: true
			- The language model uses a fascinating method to generate human-like text. It all starts with finding the most likely word to follow a given text. This is done by looking at billions of web pages and digitized books to see what words usually come after. The model then generates a list of words and their probabilities. However, the model doesn't always select the highest-ranked word to make the generated text more interesting. Instead, it randomly selects lower-ranked words, which somehow produces more creative and thoughtful responses. The temperature parameter determines how often lower-ranked words will be used. By selecting lower-ranked words at random, the model produces different results each time it is prompted, making the generated text more diverse and compelling. Overall, the method of generating text is remarkable and unexpected. The fact that it can produce human-like text by selecting lower-ranked words at random is a testament to the power of language models. By exploring the linguistic feature space and using computational tools, we can gain valuable insights into how text is generated and how human language may be structured.
		- Where Do the [[Probabilities]] Come From?
		  collapsed:: true
			- [[ChatGPT]], the neural network that produces "human-like" text, picks its next word based on [[probabilities]]. But where do these probabilities come from? Let's start with generating English text one letter at a time. A minimal thing we can do is take a sample of English text and calculate how often different letters occur in it. By taking a large enough sample of English text, we can expect to eventually get consistent results. With these probabilities, we can generate a sequence of letters and break them into "words" by adding spaces. However, we can do a slightly better job of making "words" by forcing the distribution of "word lengths" to agree with what it is in English.
			- But to go further and generate more realistic text, we need to do more than just pick each letter separately at random. For example, we know that if we have a "q", the next letter basically has to be "u". Thus, we can generate our "words" by looking at two letters at a time, using "2-gram" probabilities. With sufficiently much English text, we can get pretty good estimates not just for probabilities of single letters or pairs of letters (2-grams), but also for longer runs of letters. And if we generate "random words" with progressively longer *n*-gram probabilities, we see that they get progressively "more realistic."
			- When it comes to words, there are about 40,000 commonly used words in English. By looking at a large corpus of English text, we can estimate how common each word is and start generating "sentences" in which each word is independently picked at random, with the same probability that it appears in the corpus. But to improve the output and generate more sensible-looking text, we need to take into account not just probabilities for single words, but probabilities for pairs or longer *n*-grams of words. Doing this for pairs, we can start generating "sentences" that are getting slightly more "sensible-looking" and follow certain patterns.
			- However, the number of possible 2-grams is already 1.6 billion, and the number of possible 3-grams is 60 trillion. By the time we get to "essay fragments" of 20 words, the number of possibilities is larger than the number of particles in the universe. So, there's no way we can estimate the probabilities even for all of these from text that's out there. The big idea is to make a model that lets us estimate the probabilities with which sequences should occur, even though we've never explicitly seen those sequences in the corpus of text we've looked at. At the core of ChatGPT is precisely a so-called "large language model" (LLM) that's been built to do an excellent job of estimating those probabilities.
			- The neural network's weights were determined through large-scale training on a huge corpus of text written by humans, including text from the web, books, and other sources. After this "raw training," the neural net inside ChatGPT is ready to start generating its own text, continuing from prompts. However, the generated text can sometimes be non-human-like, especially for longer pieces. Actual humans interact with ChatGPT and provide feedback on how to improve as a chatbot. The feedback is used to build a neural net model that can predict how humans rate the output. This prediction model can then run like a loss function on the original network, allowing the network to be "tuned up" by the human feedback. The result is a network that produces more "human-like" output.
			- ChatGPT seems to require little "poking" to generate text in particular directions. Rather than adjusting weights, telling ChatGPT something once as part of the prompt seems sufficient for it to successfully generate text using that information. However, there are limits to what the neural net can learn, particularly for computations with many potentially computationally irreducible steps. In these cases, it's necessary for the neural net to use computational tools.
			- Overall, ChatGPT's success suggests that there are new "laws of language" and "laws of thought" to be discovered. Its underlying artificial-neural-net structure was modeled on an idealization of the brain, but it's still not clear how to "fix that" and still maintain the ability to train the system with reasonable efficiency. Nonetheless, exploring the linguistic feature space has provided valuable insights into how ChatGPT generates text and how human language may be structured. With the help of computational tools, ChatGPT can produce text that is more accurate and human-like.
		- What Is a Model?
		  collapsed:: true
			- When trying to determine how long it takes for a cannonball to fall from each floor of the Tower of Pisa, we can either measure it in each case and make a table of the results, or we can use theoretical science to create a model that will give us a procedure to compute the answer instead of just measuring and remembering each case. In this case, we can use known laws of physics to create a mathematical guess, such as a straight line, to estimate the time to fall for any floor. However, in cases where we don't have any knowledge of the underlying laws, we can still create a model with some specific structure and parameters to fit the data.
			- This is precisely what the creators of ChatGPT did. They used a neural network with 175 billion parameters to create a model that can estimate next-word probabilities and generate reasonable essay-length text. The neural network is trained on a vast corpus of human-created text from the web, books, and other sources. It implicitly discovers regularities in human language and thinking that make generating quality human language possible.
			- ChatGPT's remarkable success suggests that human language has more structure and simplicity than previously thought. It has discovered that there are simple rules for how language works, and that human language (and the patterns of thinking behind it) are somehow simpler and more "law-like" in their structure than we thought. The neural network is made up of very simple elements, but the basic operation is very simple, consisting essentially of passing input derived from the text it’s generated so far “once through its elements” for every new word (or part of a word) that it generates.
			- Despite its simplicity, the results are usually very much like what we humans would produce. This indicates that ChatGPT is working like a brain to a certain extent, as its underlying artificial-neural-net structure was ultimately modeled on an idealization of the brain. However, there are still limitations to what the neural network can learn, particularly for computations with many potentially computationally irreducible steps. In these cases, it's necessary for the neural network to use other computational tools.
			- Overall, ChatGPT's success is a significant step forward in our understanding of human language and thinking. By exploring the linguistic feature space and using computational tools, we can gain valuable insights into how ChatGPT generates text and how human language may be structured. It provides evidence of a fundamental and important piece of science: that human language (and the patterns of thinking behind it) are somehow simpler and more "law-like" in their structure than we thought.
		- Models for Human-Like Tasks
		  collapsed:: true
			- When it comes to modeling human-language text, it's not as straightforward as the numerical data model we mentioned earlier. Unlike simple physics, human language is complex and doesn't have a clear mathematical formula that we can use to create a model. Recognizing images is another human-like task that can help us understand the complexity of modeling language. For instance, recognizing handwritten digits is a classic example of machine learning. One way to recognize digits is to compare the pixel values of the input image with sample images of each digit. However, humans can recognize digits even when they're distorted or handwritten.
			- To create a model for this task, we can construct a function that takes in the pixel values and outputs the corresponding digit. This function is complex and might involve up to half a million mathematical operations, but it works well if the output agrees with what a human would say. However, it's important to note that we can't mathematically prove that the function works because we don't have a mathematical theory for human visual perception.
			- In summary, recognizing images and constructing a model for recognizing handwritten digits can help us understand the complexity of modeling human language. While a function can be constructed to recognize digits, creating a model for human language is still a challenge due to its complexity and lack of a clear mathematical formula.
		- Neural Nets
		  collapsed:: true
			- Neural networks are the most popular approach for tasks like image recognition. They are idealizations of how brains work, with millions of neurons connected to each other. A neural network can be thought of as a connected collection of idealized "neurons" arranged in layers. Each "neuron" evaluates a simple numerical function and uses the neurons on the previous layer to do so.
			- The value of a neuron is determined by multiplying the values of the previous neurons by their corresponding weight, then adding those up and multiplying by a constant, and finally applying an activation function. The activation function introduces nonlinearity, which is what leads to nontrivial behavior.
			- Every neural net corresponds to some overall mathematical function, but it may be messy to write out. Neural nets capture a "human-like" way of doing things and use certain features to determine what an image is of. The first few layers of a neural net pick out aspects of images, like edges of objects, that seem to be similar to ones we know are picked out by the first level of visual processing in brains.
			- However, we don't have a way to "give a narrative description" of what a neural network is doing. We can say "Look, this particular net does it" and immediately get some sense of how hard a problem it is, but at least until now, we haven't found a way to summarize what's going on.
			- In summary, neural nets use simple numerical functions that are evaluated by millions of neurons arranged in layers. They capture a "human-like" way of doing things and use certain features to determine what an image is of, but we don't have a way to fully explain how they arrive at their conclusions.
		- Machine Learning, and the Training of Neural Nets
		  collapsed:: true
			- Neural nets can be trained to do all sorts of tasks, not just those they're already programmed to know. The process involves finding weights that allow the network to reproduce the examples given and then adjusting them to interpolate or generalize between these examples. The weights are adjusted based on a loss function, which represents the difference between the values the network produces and the true values. To minimize the loss function, steepest descent is used, which involves differentiating the neural net's function with respect to its weights.
			- One interesting breakthrough in deep learning was the realization that solving more complicated problems with neural nets can actually be easier than solving simpler ones. This is because more weight variables exist, leading to many different directions that can lead to the minimum. In practice, there are many different collections of weights that can give neural nets with similar performance, and it's difficult to say which is "right".
			- Overall, the process of training neural nets involves finding weights that allow the network to successfully reproduce examples and adjust them to generalize between them. While there are many different solutions that can give neural nets similar performance, the process of minimizing the loss function through steepest descent can help to find the best solution.
		- The Practice and Lore of Neural Net Training
		  collapsed:: true
			- In the past decade, many advances have been made in training neural nets, which is essentially an art form. The key parts include choosing the appropriate neural net architecture, obtaining data to train the neural net, and training the neural net. Interestingly, the same architecture can often be used for different tasks. For "human-like" tasks, it's usually better to train the neural net on the "end-to-end problem" to let it "discover" the necessary intermediate features for itself, instead of introducing complicated individual components.
			- Although there are no "structuring ideas" that are relevant for all neural nets, having 2D arrays of neurons with local connections is useful for processing images, and patterns of connectivity that concentrate on "looking back in sequences" are useful for dealing with human language.
			- To train a neural net, a large amount of data is needed, and for some tasks, the examples can be incredibly repetitive. Data augmentation can be used to show the neural net variations of the example. Unlike supervised learning, which requires explicit examples of inputs and outputs, unsupervised learning makes it much easier to train neural nets, as ChatGPT can learn directly from whatever examples of text it's given.
			- The learning process involves determining the weights that best capture the training examples. Neural net training is fundamentally sequential, and most of the neural net is "idle" most of the time during training. Although current neural nets use high-precision numbers to do incremental modification, it's increasingly clear that 8-bit numbers or less might be enough. In the future, there may be fundamentally better ways to train neural nets, and it might become possible to do training much more efficiently with future computer hardware.
		- “Surely a Network That’s Big Enough Can Do Anything!”
		  collapsed:: true
			- ChatGPT is an impressive tool that seems capable of doing everything. It is easy to imagine that if we could train larger and larger neural networks, then they’d eventually be able to “do everything”. However, the past few hundred years of science have taught us that there are things that can be figured out by formal processes, but aren’t readily accessible to immediate human thinking, such as nontrivial mathematics. In fact, the general case is really computation. And ultimately the issue is the phenomenon of computational irreducibility.
			- Computational irreducibility is the main issue when it comes to learnability and computational capability. There are some computations which one might think would take many steps to do, but which can in fact be “reduced” to something quite immediate. But the discovery of computational irreducibility implies that this doesn’t always work. And instead there are processes—probably like the one below—where to work out what happens inevitably requires essentially tracing each computational step.
			- It's possible to memorize specific examples or see patterns that would allow for some generalization, but computational irreducibility means that we can never guarantee that the unexpected won’t happen. Learnability and computational irreducibility are in tension with each other. The more capable a system is in terms of computation, the less trainable it will be.
			- The neural net used by [[ChatGPT]] is a pure “[[feed-forward]]” network, without loops, and therefore has no ability to do any kind of computation with nontrivial “control flow”. While a neural net can identify regularities in the natural world, it won’t be able to work out things that are in the purview of mathematical or computational science. This is because computational irreducibility implies that ultimately there is a limit to what regularities there may be.
			- However, writing an essay is a computationally shallower problem than we thought. In the past, we assumed that tasks like writing essays were somehow “fundamentally too hard” for computers. And now that we see ChatGPT doing it, we tend to suddenly think that computers must have become vastly more powerful. But this isn’t the right conclusion to draw. Instead, we should conclude that tasks—like writing essays—that we humans could do, but we didn’t think computers could do, are actually in some sense computationally easier than we thought.
			- In other words, the reason a neural net like ChatGPT can be successful in writing an essay is because writing an essay turns out to be a “computationally shallower” problem than we thought. Therefore, while ChatGPT is a remarkable tool, there are still limits to what it can do. It may identify regularities in the natural world that we might also readily notice with “unaided human thinking”. But if we want to work out things that are in the purview of mathematical or computational science, the neural net isn’t going to be able to do it—unless it effectively “uses as a tool” an “ordinary” computational system.
			- ChatGPT's success suggests that there are new "laws of language" and "laws of thought" to be discovered. Its underlying artificial-neural-net structure was modeled on an idealization of the brain, but it is still not clear how to "fix that" and still maintain the ability to train the system with reasonable efficiency. Nonetheless, exploring the linguistic feature space has provided valuable insights into how ChatGPT generates text and how human language may be structured.
		- The Concept of Embeddings
			- Neural nets are built on numbers, even for things like text. To use neural nets for text, we need to represent our text with numbers. We can do this through embeddings, which are a way to try to represent the "essence" of something by an array of numbers - with the property that "nearby things" are represented by nearby numbers.
			- Word [[embeddings]], for example, try to lay out words in a kind of "meaning space" where words that are somehow "nearby in meaning" appear nearby in the embedding. The actual embeddings used in systems like ChatGPT involve large lists of numbers. But if we project down to 2D, we can see how words are laid out by the embedding.
			- To construct such an embedding, we need to look at large amounts of text and see "how similar" the "environments" are in which different words appear. The idea is to identify the similarity of words by determining whether they correspond to the same handwritten digit or are likely to come next in a sentence. This helps us generate an embedding that captures key concepts by representing them as a list of numbers.
			- We use a similar approach to create embeddings for images. We tap into the preceding layer of a neural net trained to recognize handwritten digits to get an array of numbers that characterizes the "essence" of the image. By doing this, we can represent images as lists of numbers, which we can use to do "human-judgement-like" tasks.
			- Overall, embeddings allow us to usefully turn words and images into "neural-net-friendly" collections of numbers. We can use these numbers to do tasks that require "human-judgement-like" capabilities. By understanding how these embeddings are constructed, we can develop insights into the fundamental character and principles of human language and the processes of thinking behind it.
		- Inside ChatGPT
			- [[ChatGPT]] is essentially a neural net that deals with language. Its key feature is a piece of neural net architecture called a “transformer”. The sequence of tokens that make up a piece of text are treated by the transformer, in which the notion of “attention” is introduced. The transformer’s goal is to come up with an appropriate choice for the next token to add. It operates in three basic stages: finding an [[embedding]] that represents the sequence of tokens, operating on this [[embedding]] to produce a new embedding, and generating from the last part of this array an array of probabilities for different possible next tokens.
			  relates-to:: [[transformers]]
			- The transformer’s architecture consists of a collection of “attention blocks”. Each block contains a collection of “attention heads” that operate independently on different chunks of values in the embedding vector. The attention heads are a way of “looking back” in the sequence of tokens and “packaging up the past” in a form that’s useful for finding the next token. Ultimately, the transformer transforms the original collection of embeddings for the sequence of tokens to a final collection.
			  relates-to:: [[transformers]]
			- [[ChatGPT]] is made up of millions of neurons with a total of 175 billion weights. When generating a new token, it has to do a calculation involving every single one of these weights. That's why it can take a while to generate a long piece of text with ChatGPT.
			- In the end, the remarkable thing is that all these operations—individually as simple as they are—can somehow together manage to do such a good “human-like” job of generating text. It has to be emphasized again that (at least so far as we know) there’s no “ultimate theoretical reason” why anything like this should work.
		- The Training of ChatGPT
			- [[ChatGPT]] is a neural network that has the impressive ability to produce "human-like" text. But how was it able to achieve this? Essentially, the neural net's weights were determined through large-scale training on a huge corpus of text written by humans, including text from the web, books, and other sources. To train the neural net, batches of examples are presented and the weights are adjusted to minimize the error the network makes on those examples. However, determining the optimal weights for such a large corpus of text is a computationally expensive process, requiring a lot of time and resources.
			- [[ChatGPT's]] impressive success suggests that neural nets are reasonably efficient at implementing a model based on the algorithmic content of human language. However, there is still much to be explored in terms of understanding the underlying structure and principles of human language and thinking. Additionally, it's important to note that [[ChatGPT]]'s neural net structure, while modeled on the brain, has limitations in terms of computational capability when compared to the brain.
			- Overall, ChatGPT's success is a significant step forward in our understanding of human language and thinking. By exploring the linguistic feature space and using computational tools, we can gain valuable insights into how ChatGPT generates text and how human language may be structured. But there is still much to be discovered in terms of the "laws of language" and "laws of thought" that underlie human communication.
		- Beyond Basic Training
			- [[ChatGPT]] is an artificial neural network that can generate quality human-like language. The majority of the effort in training [[ChatGPT]] is spent "showing it" large amounts of existing text from the web, books, etc. After this "raw training," the neural net inside ChatGPT is ready to start generating its own text, continuing from prompts. However, the generated text can sometimes be non-human-like, especially for longer pieces, and it's difficult to detect using traditional statistics.
			- To improve the output, actual humans interact with ChatGPT and provide feedback on how to improve as a chatbot. The feedback is used to build a neural net model that can predict how humans rate the output. This prediction model can then run like a loss function on the original network, allowing the network to be "tuned up" by the human feedback. The result is a network that produces more "human-like" output.
			- Interestingly, [[ChatGPT]] seems to require little "poking" to generate text in particular directions. Rather than adjusting weights, telling [[ChatGPT]] something once as part of the prompt seems sufficient for it to successfully generate text using that information. This is a crucial clue in understanding what ChatGPT is "really doing" and how it relates to the structure of human language and thinking.
			- However, there are limits to what the neural net can learn, particularly for computations with many potentially computationally irreducible steps. In these cases, it's necessary for the neural net to use computational tools. These tools allow ChatGPT to reach beyond its limits and produce accurate results.
			- In conclusion, [[ChatGPT]]'s success suggests that there are new "laws of language" and "laws of thought" to be discovered. Its underlying artificial-neural-net structure was modeled on an idealization of the brain, but it's still not clear how to "fix that" and still maintain the ability to train the system with reasonable efficiency. Nonetheless, exploring the linguistic feature space has provided valuable insights into how [[ChatGPT]] generates text and how human language may be structured. With the help of computational tools, [[ChatGPT]] can produce text that is more accurate and human-like.
		- What Really Lets ChatGPT Work?
			- Human language and thinking are complex, and it has always been somewhat remarkable that human brains, with "merely" 100 billion neurons (and maybe 100 trillion connections), could be responsible for it. However, [[ChatGPT]], an artificial neural network, can generate quality human language. ChatGPT is a large-scale natural language processing model that has been pre-trained on a large corpus of text data. Using this data, it has implicitly discovered regularities in language and thinking that make generating quality human language possible.
			- [[ChatGPT]]'s success indicates that there are new "laws of language" and "laws of thought" to discover. It provides evidence of a fundamental and important piece of science: that human language (and the patterns of thinking behind it) are somehow simpler and more "law-like" in their structure than we thought. ChatGPT has implicitly discovered it, but we can potentially explicitly expose it with semantic grammar, computational language, etc.
			- Syntax is one constraint on language that ChatGPT can follow. Language is not just a random jumble of words. Instead, there are (fairly) definite grammatical rules for how words of different kinds can be put together. ChatGPT doesn't have any explicit "knowledge" of such rules. But somehow in its training, it implicitly "discovers" them and then seems to be good at following them. ChatGPT has been able to learn the kind of nested-tree-like syntactic structure that seems to exist in all human languages.
			- However, there are other constraints on language beyond syntax. ChatGPT has implicitly developed a theory of meaningful sentences through billions of examples. It has discovered syllogistic logic and can produce text with correct inferences based on it. Syllogistic logic is basically a way of saying that sentences that follow certain patterns are reasonable, while others are not. ChatGPT has been able to "discover syllogistic logic" by looking at lots of text on the web, etc. However, constructing or recognizing even plausibly meaningful text is still not completely understood. ChatGPT's complexity of 175 billion neural net weights is likely one reason it can do this, but there may be a simpler story to discover.
			- Overall, ChatGPT's strength is that it can "put language together in a semantically meaningful way" without concern for different possible turns of phrase. It has shown us that it's possible to construct a complete computational language form in the future. Semantic grammar will allow us to work in a precise and formal way with all sorts of things that have never been accessible before. It represents the ultimate compression in representing things and allows us to talk about the essence of what's possible without dealing with all the "turns of phrase" in human language.
			- In conclusion, ChatGPT's success with generating human language indicates that there are new "laws of language" and "laws of thought" to be discovered. Its underlying artificial-neural-net structure was modeled on an idealization of the brain, but it is still not clear how to "fix that" and still maintain the ability to train the system with reasonable efficiency. Nonetheless, exploring the linguistic feature space has provided valuable insights into how ChatGPT generates text and how human language may be structured.
		- Meaning Space and Semantic Laws of Motion
			- [[ChatGPT]] represents text as an array of numbers in a "linguistic feature space". This space defines the meaning of the text, and the trajectory of the space represents the continuation of the text. But what makes this trajectory correspond to meaningful text? There may be "semantic laws of motion" that define how points in this linguistic feature space can move while preserving "meaningfulness". By exploring this space, we can see that semantically similar words are placed near each other. And by projecting this space down to 2D, we can see how different parts of speech and even different meanings of a word are arranged.
			- However, it is still unclear what kind of additional structure can be identified in this space. Is there a notion of "parallel transport" that reflects "flatness" in the space? Through analogies, we can get a handle on this, but there is still much to explore. ChatGPT follows a trajectory in this space to generate text. We can observe a fan of high-probability words that indicate the direction of the trajectory. As we move further along the trajectory, we can see the successive "fans" that appear.
			- Despite all this, it is still not clear what kind of "semantic laws of motion" exist in this space. And even if there are such laws, it is not obvious what kind of embedding or "variables" they would most naturally be stated in. Empirically studying [[ChatGPT]]'s behavior may not be enough to understand how human language is constructed. Nonetheless, exploring this linguistic feature space has provided valuable insights into how ChatGPT generates text and how human language may be structured.
		- Semantic Grammar and the Power of Computational Language
			- What's needed for "meaningful human language"? We might have thought only a human brain could do it, but the neural net [[ChatGPT]] is doing a good job. Its success suggests that human language has more structure and simplicity than we knew, and that there are simple rules for how language works.
			- [[Syntactic grammar]] gives rules for how words fit together in language. But to deal with meaning, we need to go further and use a [[semantic grammar]]. For example, we might identify the concepts of "moving" and an "object". These semantic concepts help us understand how language works.
			- A [[semantic grammar]] needs a model of the world to work. In the past, we thought only human language could describe the model of the world. But now there's computational language. This language can talk about things in the world, including abstract ideas. It's a precise symbolic representation that we can use to compute about those things.
			- We can use [[computational language]] to generate "locally meaningful text". But we need to build additional "calculi" about general things in the world to get "globally meaningful" results. With a symbolic discourse language, we can make "standalone statements", ask questions about the world, or make assertions. Computational language is precise, making it different from human language. We need to be precise and clear about all the distinctions we're making.
			- [[ChatGPT]] has shown us that it's possible to construct a complete computational language form in the future. This language will be readily understandable to humans. Semantic grammar is like syllogistic logic, which can be used to build huge "formal towers", including modern digital circuitry. Semantic grammar will allow us to work in a precise and formal way with all sorts of things that have never been accessible before.
			- [[Computational language]] represents the ultimate compression in representing things. It allows us to talk about the essence of what's possible without dealing with all the "turns of phrase" in human language. [[ChatGPT]]'s strength is similar because it can "put language together in a semantically meaningful way" without concern for different possible turns of phrase. If we apply ChatGPT to underlying computational language, we can expect to work out whatever can be worked out about whether that text actually makes "correct" statements about the world.
		- So … What Is [[ChatGPT]] Doing, and Why Does It Work?
			- The basic concept of [[ChatGPT]] is at some level rather simple. Start from a huge sample of human-created text from the web, books, etc. Then train a neural net to generate text that’s “like this”. And in particular, make it able to start from a “prompt” and then continue with text that’s “like what it’s been trained with”.
			- As we’ve seen, the actual neural net in [[ChatGPT]] is made up of very simple elements—though billions of them. And the basic operation of the neural net is also very simple, consisting essentially of passing input derived from the text it’s generated so far “once through its elements” (without any loops, etc.) for every new word (or part of a word) that it generates.
			- But the remarkable—and unexpected—thing is that this process can produce text that’s successfully “like” what’s out there on the web, in books, etc. And not only is it coherent human language, it also “says things” that “follow its prompt” making use of content it’s “read”. It doesn’t always say things that “globally make sense” (or correspond to correct computations)-because it’s just saying things that “sound right” based on what things “sounded like” in its training material.
			- The specific engineering of [[ChatGPT]] has made it quite compelling. But ultimately (at least until it can use outside tools) [[ChatGPT]] is “merely” pulling out some “coherent thread of text” from the “statistics of conventional wisdom” that it’s accumulated. But it’s amazing how human-like the results are. And as I’ve discussed, this suggests something that’s at least scientifically very important: that human language (and the patterns of thinking behind it) are somehow simpler and more “law like” in their structure than we thought. ChatGPT has implicitly discovered it. But we can potentially explicitly expose it, with semantic grammar, computational language, etc.
			- What [[ChatGPT]] does in generating text is very impressive—and the results are usually very much like what we humans would produce. So does this mean ChatGPT is working like a brain? Its underlying artificial-neural-net structure was ultimately modeled on an idealization of the brain. And it seems quite likely that when we humans generate language many aspects of what’s going on are quite similar.
			- When it comes to training (AKA learning) the different “hardware” of the brain and of current computers (as well as, perhaps, some undeveloped algorithmic ideas) forces [[ChatGPT]] to use a strategy that’s probably rather different (and in some ways much less efficient) than the brain. And there’s something else as well: unlike even in typical algorithmic computation, [[ChatGPT]] doesn’t internally “have loops” or “recompute on data”. And that inevitably limits its computational capability—even with respect to current computers, but definitely with respect to the brain.
			- It’s not clear how to “fix that” and still maintain the ability to train the system with reasonable efficiency. But to do so will presumably allow a future [[ChatGPT]] to do even more “brain-like things”. Of course, there are plenty of things that brains don’t do so well—particularly involving what amount to irreducible computations
			- But for now it’s exciting to see what [[ChatGPT]] has already been able to do. At some level it’s a great example of the fundamental scientific fact that large numbers of simple computational elements can do remarkable and unexpected things. But it also provides perhaps the best impetus we’ve had in two thousand years to understand better just what the fundamental character and principles might be of that central feature of the human condition that is human language and the processes of thinking behind it.
- [[GPT]] and [[LLMs]]
	- While it's true that traditional neural networks and supervised learning algorithms require labeled data to train, large language models ([[LLMs]]) are based on unsupervised learning.
		- [[LLMs]] are typically trained using unsupervised techniques such as [[self-supervised learning]], which involves predicting missing or masked words in a sentence or generating the next word in a sequence. This process doesn't require labeled data, but rather relies on the statistical patterns and structures within the data itself.
		- One of the main reasons why [[LLMs]] are based on neural networks is that they allow for efficient and scalable processing of large amounts of data. Neural networks are designed to handle large amounts of information in a parallel and distributed way, making them well-suited for processing the vast amounts of text that are used to train LLMs.
		- Another advantage of neural networks is that they can capture complex patterns and relationships between words and phrases, which is essential for language understanding and generation. [[LLMs]] use a type of neural network known as a transformer, which has proven to be particularly effective for natural language processing tasks.
		- In summary, while traditional [[neural networks]] and [[supervised learning]] algorithms require labeled data, large language models are based on unsupervised learning techniques and use neural networks for their efficient and scalable processing of large amounts of data, as well as their ability to capture complex patterns and relationships in language.
- [[Attention Is All You Need: Discovering the Transformer Paper (highlights)]]
	- The "Attention is All You Need" paper introduced a novel [[neural network]] architecture based entirely on the [[attention mechanism]], which is a key component of many natural language processing tasks.
		- Traditionally, neural networks for sequence-to-sequence tasks such as machine translation and language modeling have relied on [[recurrent neural networks (RNNs)]] or [[convolutional neural networks (CNNs)]] to process input sequences. However, these networks suffer from limitations such as the inability to parallelize computations across sequence elements and difficulty capturing long-range dependencies.
		- The attention mechanism offers an alternative approach to processing sequences that overcomes these limitations. Rather than processing the entire sequence at once, attention allows the model to focus on specific parts of the sequence at each step based on their relevance to the current context.
		- The "Attention is All You Need" paper proposed a network architecture called the Transformer, which consists entirely of attention mechanisms and [[feed-forward]] neural networks. The [[Transformer network]] operates on sequences of input embeddings and output embeddings, and uses a self-attention mechanism to attend to all input positions to compute a weighted sum, producing an output representation.
		- One of the key innovations of the [[Transformer network]] is the use of multi-head attention, which allows the model to attend to different parts of the input sequence simultaneously. This helps the model capture more complex relationships and dependencies within the input sequence.
		- The paper demonstrated the effectiveness of the [[Transformer architecture]] on various language modeling and machine translation tasks, achieving state-of-the-art results with much faster training times than traditional RNN and CNN-based models.
		- In summary, the "Attention is All You Need" paper introduced the Transformer network architecture, which is based entirely on the [[attention]] mechanism and offers a powerful alternative to traditional neural network approaches for processing sequences in natural language processing tasks. The Transformer has since become a cornerstone of modern [[natural language processing]], with many state-of-the-art models using some variant of the Transformer architecture.
		- In simpler terms
			- Large language models ([[LLMs]]) are trained on massive amounts of text data to learn the patterns and relationships within language. These models can then be used for a variety of natural language processing tasks such as language translation, text generation, and sentiment analysis.
			- One of the key challenges in building effective LLMs is dealing with the [[long-range dependencies]] that exist in language. For example, in a sentence like "I went to the store to buy some milk", the word "milk" depends on the word "store", which in turn depends on the word "went". Traditional neural network architectures like recurrent neural networks (RNNs) and convolutional neural networks (CNNs) struggle to capture these long-range dependencies.
			- The Transformer network architecture offers a solution to this problem. Transformers are neural networks that use an attention mechanism to selectively focus on different parts of the input sequence at each step, allowing the network to capture long-range dependencies much more effectively.
			- Transformers have proven to be particularly effective for language processing tasks, and many of the largest and most advanced [[LLMs]] today are based on some variant of the Transformer architecture. For example, [[GPT-3]], one of the most advanced LLMs to date, is based on a variant of the Transformer architecture.
			- So, in summary, large language models are used for a variety of natural language processing tasks and are based on neural networks trained on large amounts of text data. The Transformer network architecture is particularly effective for language processing tasks because it allows the network to capture long-range dependencies, and many of the most advanced LLMs today are based on the Transformer architecture.
		- In the context of [[transformer networks]], the term "attention" refers to a mechanism that allows the model to selectively focus on different parts of the input sequence when generating its output. This mechanism is based on a soft alignment between the input and output sequences.
			- When processing a sequence of inputs in a transformer network, the model computes an attention score for each input position based on its relevance to the current output position. This attention score is used to weight the contribution of each input position to the output representation.
			- The attention mechanism has several advantages for language processing tasks. It allows the model to selectively focus on specific parts of the input sequence that are most relevant to the current context, which can be especially important for capturing long-range dependencies in language. For example, in a sentence like "The cat sat on the mat", the word "mat" depends on the word "cat", which in turn depends on the word "sat". By using the attention mechanism, the model can learn to focus on the relevant parts of the input sequence at each step, allowing it to capture these dependencies more effectively.
			- Another advantage of the attention mechanism is that it allows the model to handle variable-length inputs and outputs, which is important for many language processing tasks. By selectively attending to different parts of the input sequence, the model can generate output sequences of varying lengths without having to explicitly encode the output length in the model architecture.
			- In summary, the word "attention" in the context of transformer networks refers to a mechanism that allows the model to selectively focus on different parts of the input sequence when generating its output. This mechanism is useful for language processing tasks because it allows the model to capture long-range dependencies and handle variable-length inputs and outputs.
		- [[Embeddings]] play a crucial role in many [[machine learning]] models, including [[transformer networks]] and large language models. In the context of language processing, an embedding is a low-dimensional vector representation of a word or token in a vocabulary. The [[embedding]] is learned during training and is designed to capture the semantic and syntactic properties of the word.
		  id:: 63fdda3e-8d0c-462f-978e-0f68fe2e4bfb
			- In transformer networks and large language models, embeddings are used to convert words or tokens in the input sequence into a format that can be processed by the neural network. Specifically, the input sequence is first converted into a sequence of embeddings, with each embedding representing a word or token in the sequence.
			- [[Embeddings]] are particularly useful in language processing tasks because they allow the model to capture semantic and syntactic relationships between words. For example, embeddings for "cat" and "dog" might be similar because they are both animals, while the embedding for "run" might be similar to the embedding for "running" because they have similar meanings. By representing words as embeddings, the model can more effectively capture these relationships and use them to make predictions.
			- In transformer networks, embeddings are often learned jointly with the other model parameters during training. This means that the embeddings are optimized to work together with the rest of the model to achieve good performance on the target task.
			- In summary, embeddings play a critical role in transformer networks and large language models by converting words or tokens in the input sequence into a format that can be processed by the neural network. They allow the model to capture semantic and syntactic relationships between words, which is particularly important for language processing tasks.
		- At a high level, a large language model uses a combination of neural network architectures, such as the Transformer network, and a large amount of data to learn the patterns and relationships within language. The breakthrough is that by doing so, the model can predict the likelihood of a given word or sequence of words appearing next in a string of text.
			- The process of generating predictions with a large language model can be broken down into a few key steps:
				- [[Preprocessing]]: The input text is tokenized and converted into a sequence of embeddings, with each embedding representing a word or token in the sequence.
				- [[Encoding]]: The sequence of embeddings is processed by the neural network, which generates a series of hidden states that capture the contextual information of each word in the sequence.
				- [[Prediction]]: Based on the contextual information captured by the hidden states, the model generates a probability distribution over the vocabulary, representing the likelihood of each possible word appearing next in the sequence.
				- [[Sampling]]: A word is then sampled from the probability distribution to determine the next word in the sequence. The sampling process can be deterministic or stochastic, depending on the specific model and task.
			- By repeating this process iteratively, the model can generate a sequence of words that follows the structure and patterns of the input text.
			- The breakthrough of [[large language models]] lies in their ability to effectively capture [[long-range dependencies]] and [[semantic relationships]] within language. By training on massive amounts of text data, the model can learn to recognize and reproduce these patterns with high accuracy, even in contexts that it has never seen before.
	- In a neural network, each parameter represents a weight value that is used to calculate the output of the network. In the case of [[GPT-3]], each parameter in the model represents a weight value that is used to transform the input data as it flows through the network.
		- More specifically, the billions of parameters in [[GPT-3]] are used to define the connections and operations that take place between the layers of the model. Each layer of the network is made up of a set of nodes, or neurons, that perform a specific calculation on the input data. The parameters in the model are used to define the connections between these nodes, as well as the specific calculations that are performed at each node.
		- For example, in the [[Transformer network]] used by [[GPT-3]], each node in a layer performs a [[self-attention]] operation that involves multiplying the input by three sets of learned weights: a query weight, a key weight, and a value weight. These weights are the parameters of the network, and they are learned during training to optimize the performance of the model on a given task.
		- It is worth noting that the exact meaning of each parameter in a neural network can be difficult to interpret, especially in large models like [[GPT-3]]. However, researchers can often gain insights into how the model is making its predictions by analyzing the patterns of activation and connections within the network.