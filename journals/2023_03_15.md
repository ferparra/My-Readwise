- [[LLMs]]
	- [[Softmax]] is a function that turns a vector of real values into a vector of probabilities that sum to 1¹. It is often used as the last activation function of a neural network to produce a probability distribution over classes³.
	- A [[transformer model]] is a [[neural network]] that learns context and meaning by tracking relationships in sequential data like words or pixels⁵. It uses attention mechanisms to encode and decode the input and output sequences⁷.
	- Modern LLM models are language models that use transformer architectures to generate natural language texts. They can be trained on large corpora of text data and fine-tuned for specific tasks like text summarization, translation, or question answering. Some examples of LLM models are GPT-3, BERT, and T5.
	- Do you want me to explain more about any of these concepts?
	  Source: Conversation with Bing, 15/03/2023(1) Softmax Function Definition | DeepAI. https://deepai.org/machine-learning-glossary-and-terms/softmax-layer Accessed 15/03/2023.
	  (2) Softmax function - Wikipedia. https://en.wikipedia.org/wiki/Softmax_function Accessed 15/03/2023.
	  (3) What Is a Transformer Model? | NVIDIA Blogs. https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/ Accessed 15/03/2023.
	  (4) Transformer (machine learning model) - Wikipedia. https://en.wikipedia.org/wiki/Transformer_(machine_learning_model) Accessed 15/03/2023.
	  (5) Softmax Activation Function — How It Actually Works. https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78 Accessed 15/03/2023.
	  (6) 一文详解Softmax函数 - 知乎. https://zhuanlan.zhihu.com/p/105722023 Accessed 15/03/2023.
	  (7) The Ultimate Guide to Transformer Deep Learning - Turing. https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power Accessed 15/03/2023.
	  (8) Training the Transformer Model - MachineLearningMastery.com. https://machinelearningmastery.com/training-the-transformer-model/ Accessed 15/03/2023.
	- [[Attention mechanisms]] are a way to retrieve relevant information from a sequence of inputs by assigning different weights to each input¹². They can help the model focus on the most important parts of the input and output sequences³.
	- There are different types of attention mechanisms, such as dot-product attention, additive attention, and [[multi-head attention]]⁴⁵. They differ in how they compute the weights and how they combine the weighted inputs.
	- One common attention mechanism used in transformer models is scaled dot-product attention. It computes a dot product for each query with all of the keys, divides each result by the square root of the key dimension, and applies a softmax function to get the weights. Then it multiplies each value by its corresponding weight and sums them up to get the output⁵.
	- Do you have any questions about attention mechanisms?
	  Source: Conversation with Bing, 15/03/2023(1) NLP: what is attention mechanism? - DataJello.com. https://datajello.com/nlp-what-is-attention-mechanism/ Accessed 15/03/2023.
	  (2) Attention Mechanism - FloydHub Blog. https://blog.floydhub.com/attention-mechanism/ Accessed 15/03/2023.
	  (3) The Attention Mechanism from Scratch - Machine Learning Mastery. https://machinelearningmastery.com/the-attention-mechanism-from-scratch/ Accessed 15/03/2023.
	  (4) Attention (machine learning) - Wikipedia. https://en.wikipedia.org/wiki/Attention_(machine_learning) Accessed 15/03/2023.
	  (5) The Transformer Attention Mechanism - MachineLearningMastery.com. https://machinelearningmastery.com/the-transformer-attention-mechanism/ Accessed 15/03/2023.
	- [[Multi-head attention]] is a type of [[attention mechanism]] that runs through an attention function several times in parallel². It splits the queries, keys, and values into multiple heads, applies scaled dot-product attention to each head, and concatenates and transforms the outputs³.
	- [[Multi-head attention]] allows for attending to different parts of the sequence differently. For example, some heads may focus on longer-term dependencies while others may focus on shorter-term dependencies². It also increases the model capacity and expressiveness by learning different representations of the inputs¹.
	- Do you want me to explain more about multi-head attention?
	  Source: Conversation with Bing, 15/03/2023(1) Multi-Head Attention Explained | Papers With Code. https://paperswithcode.com/method/multi-head-attention Accessed 15/03/2023.
	  (2) The Transformer Attention Mechanism - MachineLearningMastery.com. https://machinelearningmastery.com/the-transformer-attention-mechanism/ Accessed 15/03/2023.
	  (3) Explained: Multi-head Attention (Part 1) - Erik Storrs. https://storrs.io/attention/ Accessed 15/03/2023.
	- [[Pre-training]] and [[fine-tuning]] are two stages of training LLM models. [[Pre-training]] involves learning general language representations from large amounts of unlabeled text data. [[Fine-tuning]] involves adapting the pre-trained model to a specific task or domain by adding task-specific layers and updating the model parameters with labeled data.
	- Some methods to evaluate the performance and quality of LLM models are intrinsic and extrinsic evaluation. [[Intrinsic evaluation]] measures how well the model captures linguistic properties or knowledge, such as perplexity, accuracy, or coherence. [[Extrinsic evaluation]] measures how well the model performs on downstream tasks or applications, such as text summarization, translation, or question answering.
	- Some challenges and limitations of LLM models in terms of scalability, robustness, and generalization are:
		- [[Scalability]]: LLM models require a lot of computational resources and memory to train and run on large datasets and vocabularies. They also face issues with data efficiency and sample complexity.
		- [[Robustness]]: LLM models are vulnerable to noise, adversarial attacks, or out-of-distribution inputs that can degrade their performance or cause them to produce erroneous outputs.
		- [[Generalization]]: LLM models may overfit to specific domains or tasks and fail to transfer their knowledge to new or unseen scenarios. They may also lack common sense reasoning or world knowledge that humans possess.
	- LLM models handle [[long-range dependencies]] and [[hierarchical structures]] in natural language texts by using [[attention mechanisms]] and [[positional encodings]]. [[Attention mechanisms]] allow the model to focus on relevant parts of the input and output sequences regardless of their distance or position. [[Positional encodings]] provide information about the order or structure of the tokens in a sequence.