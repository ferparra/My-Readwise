title:: 125. Should We Replace Umpires With Robots? (highlights)
author:: [[No Stupid Questions]]
full-title:: "125. Should We Replace Umpires With Robots?"
category:: #podcasts
url:: https://share.snipd.com/episode/2b448c81-0a67-41f7-843e-7796aaaa3cf3

- Highlights first synced by [[Readwise]] [[Feb 28th, 2023]]
	- What Is Algorithm Aversion
	  
	  Key takeaways:
	  (* People are often reluctant to use algorithms, even when they know they are better options., * There are ways to get people to use algorithms even when they have some control over the decision.)
	  
	  Transcript:
	  Speaker 1
	  So let me go back to ask you more about what you called algorithm aversion. I do see this paper here from management science by three authors, Berkeley Deepvors, Joseph Simmons and Cade Massey, who I believe is your colleague at Wharton. Yeah, two of them are Simmons and Massey. And this is called overcoming algorithm aversion. People will use imperfect algorithms if they can even slightly modify them. You familiar with that paper?
	  
	  Speaker 2
	  Yes, a bit. The beginning of this paper says very briefly because it's so well accepted now that there is such a thing as algorithm aversion that in many, many instances, decision makers don't use algorithms opting instead to rely on human judgment, even when it's pretty clear that the algorithms are better. So that's the introduction of the paper. The question then, practically speaking, is like, what could we do to get people to use the algorithms, which really are pretty handy. And the very clever series of studies establishes the following conclusion. One people have a little bit of control over what the decision ultimately is when it's not just like, well, you said you're going to use the algorithm and the algorithm says the person's admitted. So we're admitting them to college.
	  
	  Speaker 1
	  So you're saying like, if I can give a little bit of input to say, well, maybe we should also consider this a little bit more strongly.
	  
	  Speaker 2
	  Yeah, it's kind of like the idea that, you know, people would be okay with having a self-driving car or cruise control, right? As long as I know that I can put my hand on that steering wheel and I can change the direction of this car if I choose to. And so this is in a way just like a practical engineering question. Like, how do we get human beings to use computers? And what they find over a series of studies and the studies have a setup where if you're a participant, you're asked to forecast what a student's scores are on a standardized math test like the SAT. And you do this from a profile that you read of, you know, where they come from in the United States. And sometimes they take the PSAT before they took this test, how many friends do they have that are going to college. So you read this dossier and you have a choice of whether you will rely on an algorithm. So you know, we've used lots of data sets and we have come to this formula to kind of produce what we think the SAT math score will be, or you can choose not to. And I think the clever thing about the study is they had different conditions where you had varying degrees of freedom to, you know, overroll the algorithm or not overroll it. The conclusion of the study is if you have some control, almost any control, honestly, and that to me was the most surprising finding like, okay, you can change the algorithms finding or results by like a teeny teeny 1% or whatever. That was enough to get people to use the algorithm and therefore be more accurate.
	  
	  Speaker 1
	  I think every human feels awkward and stressed when we feel we don't have control over a situation, at least to some degree. I mean, I've spoken with airline pilots about this for years.
	  
	  Speaker 2
	  That's an interesting case.
	  
	  Speaker 1
	  There is a lot of automation in flying already, but people do not like the idea of getting onto a plane without a pilot, at least at this moment in time. Yeah, I don't like that idea, to be honest. And you know, I've heard the pro automation argument from a lot of pilots and other people associated with airlines, including, you know, my brother is a pilot. He's not a commercial pilot. He used to be an Air Force pilot. I didn't know that. So I often think about when you're describing this paper by Massey at all, it strikes me as very sensible in that if we can either participate in changing the algorithm or even just think we're participating in changing the algorithm, that I can see how we'd have a really different response to it. This gets to be an ethical dilemma. You know, everybody knows I'm sure the trolley problem. Yes. It's a thought experiment where you've got a trolley that's going to kill five people who are on a track and you have the ability to switch it on to a track that kills only one person. So is that the right thing to do? Because you're killing fewer. And people really struggle with this because we don't think about that mathematically. I hate to say it. I mean, I feel bad for the one person's going to get run over by the trolley. But I wish we would. I think about this in terms of autonomous vehicles. Now, autonomous vehicles are that invention that's been just around the corner for like 15 years now. Right. I talked to a bunch of people probably 10 years ago who swore that as of now, we'd certainly do a lot of traveling in autonomous cars and trucks and things like that. And it hasn't come to pass for a variety of reasons, including the fact that the science is harder on the edge cases than it might seem. The science is harder, meaning it's hard to get the autonomous vehicle to handle all possible driving scenarios. Yeah, it's what they call edge cases. It's like whether it can interfere, construction can interfere. And then there's all the other things like pedestrians, other drivers and so on and so forth. Yeah, the unexpected events that don't fit the algorithm very well. But I also think about safety and transportation. So how many people do you think are killed by car crashes, vehicle crashes globally in a year?
	  
	  Speaker 2
	  Oh my gosh, I wish Jason were here or he would know this figure. It's got to be an alarming number.
	  
	  Speaker 1
	  Name an alarming number.
	  
	  Speaker 2
	  I think it's got to be over a million.
	  
	  Speaker 1
	  Yeah, it's about a million. That's crazy. About a million people a year. A hundred eighty thousand children every year are killed around the world from vehicle crashes, roughly five hundred a day. Okay. Imagine we're in a world where most cars are driven autonomously and one of those cars gets hacked or misprogrammed or something and it runs into a playground and runs over ten kids and they're killed. What do you think the response would be? This is in a world where many of those hundred eighty thousand kids were currently getting killed each year by crashes are no longer getting killed. But if one self-driving car runs over ten cute little kids in a playground, what do you think happens?
	  
	  Speaker 2
	  Well, here I have a very strong prediction which is okay, that's the end of self-driving cars. Like we are already irrationally penalizing algorithms and robots for being imperfect when human beings are so much more imperfect.
	  
	  Speaker 1
	  Yeah. Kevin Kelly who's a gosh, he does a lot of things. He's a photographer and he's sort of a technologist, he helped create Wired magazine. He always talks about the fact that AI and all technologies, they just really sneak up on us.
	  
	  Speaker 2
	  It's very rarely all or nothing. There's like a gradual shift in how we depend on them.
	  
	  Speaker 1
	  Yeah. And so I guess what I'm hoping is that we ([TimeÂ 0:25:44](https://share.snipd.com/snip/f5582393-a496-47ea-a7a9-f891e1f4c387))