title:: Galactica Is Basically G... (highlights)
author:: [[@patrickmineault on Twitter]]
full-title:: "Galactica Is Basically G..."
category:: #tweets
url:: https://twitter.com/patrickmineault/status/1592738675456344065

- Highlights first synced by [[Readwise]] [[Nov 19th, 2022]]
	- Galactica is basically [[GPT-3]] for science. It can write whitepapers, reviews, wikipedia pages and code. It knows how to cite and how to write equations. It's kind of big deal 1/ ðŸ§µ https://t.co/8k1XTbf5Ou ([View Tweet](https://twitter.com/patrickmineault/status/1592738675456344065))
		- **Note**: Thread
	- I wrote earlier that in the future, papers will be consumed not just by grad students and search engines: AIs like @CohereAI will be able to understand and synthesize information to assist humans 2/ https://t.co/AIQYcirEYR ([View Tweet](https://twitter.com/patrickmineault/status/1592738677293056000))
	- [[GPT-3]] and other LLMs can already do this by predicting the next token in documents. An issue they have is that the scientific part of their corpus is tiny compared to the regular internet text, e.g. reddit threads. Why not just train on science? 3/ ([View Tweet](https://twitter.com/patrickmineault/status/1592738679130202113))
	- That's what Galactica does. Its size and the number of tokens it's trained on goes against the conventional wisdom of scaling laws: it's a small-ish model trained on a small-ish model number of tokens. By Chinchilla scaling laws it's overparametrized. It should work poorly. 4/ 
	  
	  ![](https://pbs.twimg.com/media/FhqGr6ZWAAEHjDq.png) ([View Tweet](https://twitter.com/patrickmineault/status/1592738683652014081))
	- But it doesn't! On a battery of general knowledge it outperforms ðŸ¤—Bloom and Meta OPT. And on scientific problems like completing LaTeX equations it rises far and above. Speculation: high quality medium data >> poor quality big data 5/ 
	  
	  ![](https://pbs.twimg.com/media/FhqHfklX0AAlZRU.jpg) 
	  
	  ![](https://pbs.twimg.com/media/FhqHz0IXoAEHOC5.jpg) ([View Tweet](https://twitter.com/patrickmineault/status/1592738688550989825))
	- It's really good at finding references based off of text. Imagine Zotero of the future where you just type a fact and it will suggest paper citations supporting that fact; or refute it! Big productivity boost for science 6/ 
	  
	  ![](https://pbs.twimg.com/media/FhqIxMCWAAISYvU.jpg) ([View Tweet](https://twitter.com/patrickmineault/status/1592738693873537025))
	- Of course, it's not quite ready for primetime, and it's not magic. They tried to predict binding affinity and molecular properties from formulas and that worked poorly compared to using 3d reps. Not really surprising 7/ 
	  
	  ![](https://pbs.twimg.com/media/FhqJRRvXkAEoZ5C.png) ([View Tweet](https://twitter.com/patrickmineault/status/1592738698093035520))
	- Nevertheless, very cool. I would love it if this type of model was embedded as a writing assistant in Overleaf or @curvenote, much like Co-pilot is in vscode. Let's relieve ourselves from the drudgery of science and focus on the good stuff! 8/8 ([View Tweet](https://twitter.com/patrickmineault/status/1592738701108711427))