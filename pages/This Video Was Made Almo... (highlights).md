title:: This Video Was Made Almo... (highlights)
author:: [[@nickfloats on Twitter]]
full-title:: "This Video Was Made Almo..."
category:: #tweets
url:: https://twitter.com/nickfloats/status/1635749064091267098

- Highlights first synced by [[Readwise]] [[Mar 16th, 2023]]
	- This video was made almost entirely by AI. 
	  
	  I used ChatGPT to write a script, Midjourney to create reference images, Runway Gen-1 to apply the style of the images to my source video, and Boomy AI for the music.
	  
	  Workflow breakdown w/ comparisons in thread.
	  
	  ðŸ§µ https://t.co/IUGyBKvqmg ([View Tweet](https://twitter.com/nickfloats/status/1635749064091267098))
		- **Note**: Thread
	- Before we get into it, here is a comparison shot of the original footage and the Gen-1 output.
	  
	  And yes, that's a roll of toilet paper lol https://t.co/om3fEjxFQI ([View Tweet](https://twitter.com/nickfloats/status/1635749066201239554))
	- Step 1 - Generate a script in ChatGPT
	  
	  I asked ChatGPT to "Write a script for a 9 second video composed of three 3 second clips. The story should feature a man in his living room and be sci-fi themed"
	  
	  This was what it gave me ðŸ‘‡ 
	  
	  ![](https://pbs.twimg.com/media/FrNScZrXgBU2Ui3.png) ([View Tweet](https://twitter.com/nickfloats/status/1635749068516343818))
	- Step 2 - Make reference image in Midjourney
	  
	  Based on the script, I asked MJ to /imagine sci-fi film still, medium shot, centered, side-angle view, a man sitting on a chair, holding a glowing orb in his hands, living room, new york, 4k --ar 16:9
	  
	  This was the image I picked ðŸ‘‡ 
	  
	  ![](https://pbs.twimg.com/media/FrNTRyBXgAM6xWd.jpg) ([View Tweet](https://twitter.com/nickfloats/status/1635749069913042944))
	- Step 3 - Capture footage on my iPhone
	  
	  I rearranged some furniture in my living room to better match the reference image in hopes of having cleaner outputs later on.
	  
	  This was the original shot of the first clip ðŸ‘‡ https://t.co/6Dt9f8GfP8 ([View Tweet](https://twitter.com/nickfloats/status/1635749072366862336))
	- Step 4 - Upload video clips & reference image to Gen-1
	  
	  Gen-1 is a tool that lets you "apply the composition and style of an image or text prompt to the structure of your source video."
	  
	  I didn't use a text prompt, but I did add --interpolate as a parameter for smoother output ðŸ‘‡ https://t.co/uCzeufmtbe ([View Tweet](https://twitter.com/nickfloats/status/1635749075416150016))
	- Step 5 - Bring clips into a video editor
	  
	  I just used iMovie for this, nothing fancy. I imported the clips, trimmed some up, and strung them together. 
	  
	  ![](https://pbs.twimg.com/media/FrNWqsPWIAQmKO2.jpg) ([View Tweet](https://twitter.com/nickfloats/status/1635749077366235136))
	- Step 6 - Source AI-generated music from Boomy
	  
	  Boomy lets you create generative music based on style and mood. The track I picked is called Trippy Harvester by Peaky Chicky. I thought it paired well with the mood of the scene. 
	  
	  ![](https://pbs.twimg.com/media/FrNXQBAXwAEclwW.jpg) ([View Tweet](https://twitter.com/nickfloats/status/1635749079786590208))
	- Final step - Add music and export
	  
	  Luckily I didn't have to edit much cause the clips aligned pretty nicely with the music. 
	  
	  The final export ðŸ‘‡ https://t.co/oprIdEyURz ([View Tweet](https://twitter.com/nickfloats/status/1635749081829060611))
	- Follow me @nickfloats
	  
	  YouTube vid coming this week (link in bio)
	  
	  More content you might like ðŸ‘‡ https://t.co/N8Gh8yoIf5 ([View Tweet](https://twitter.com/nickfloats/status/1635749083473125377))
	- BTW this took me about 3 hours in total. Most of that time was spent reshooting clips on my iPhone and testing out a bunch of different parameters in Gen-1 to try and get the smoothest output. ([View Tweet](https://twitter.com/nickfloats/status/1635751166272315394))