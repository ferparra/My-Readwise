title:: Almost Two Years After GPT-3 We've Seen Continued Scaling Of... (highlights)
author:: [[Alex Tamkin ðŸ¦£]]
full-title:: "Almost Two Years After GPT-3 We've Seen Continued Scaling Of..."
category:: #articles
url:: https://twitter.com/AlexTamkin/status/1540123808735973376
document_note:: The text discusses four possible futures for the competitive dynamics of large language models (LLMs) over the next few years. These include commoditization, market specialization via private data, dominance through data flywheels, and disillusionment. Each of these scenarios has its own challenges and could lead to different outcomes.

- Highlights first synced by [[Readwise]] [[Feb 25th, 2023]]
	- Current LLMs are mostly trained on publicly available sources, like wikipedia, blogposts, GitHub, online books, etc.
	  
	  GPT-3 was trained on 570GB of such text (for perspective, that's barely enough to fill half of this microSD card). ([View Highlight](https://read.readwise.io/read/01gt3sky3nkvx3gsxscqxsn57g))
	- Firms might gain a temporary edge by scaling up their model/data/context length/retrieval bank ([View Highlight](https://read.readwise.io/read/01gt3smrervz831qrawke4jk8x))
	- Market specialization via private data
	  
	  To stave off commoditization, firms might focus on building LLMs for specific applications where private data gives a competitive edge
	  
	  For example, a software company with a large, private codebase might build superior code LLMs ([View Highlight](https://read.readwise.io/read/01gt3sn8h6mst8xs16mzddjvrp))
	- Dominance through Data Flywheels (aka "Neural Network Effects")
	  
	  Another way to prevent commoditization is to build data flywheels, where user behavior creates unique training data not accessible to competitors ([View Highlight](https://read.readwise.io/read/01gt3snjyn3pptragrgc37swev))
	- Disillusionment
	  
	  LLMs (and neural networks in general) have formidable problems, and there is no guarantee they will be solved soon
	  
	  For example, even with today's best mitigations, LLMs still sometimes output false/toxic text and insecure/incorrect code ([View Highlight](https://read.readwise.io/read/01gt3sp16yzcmxdrxpg55aec4k))