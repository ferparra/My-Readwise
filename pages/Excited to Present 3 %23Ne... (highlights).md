title:: Excited to Present 3 #Ne... (highlights)
author:: [[@jayelmnop on Twitter]]
full-title:: "Excited to Present 3 \#Ne..."
category:: #tweets
url:: https://twitter.com/jayelmnop/status/1594817513556254725

- Highlights first synced by [[Readwise]] [[Nov 22nd, 2022]]
	- Excited to present 3 #NeurIPS2022 papers on a trend I've been very excited about recently: blurring the boundaries between language models and RL agents
	  
	  (+a bonus 4th paper on active learning!)
	  
	  üßµ(0/7)
	  
	  PS: I'm on the industry job market! 
	  
	  ![](https://pbs.twimg.com/media/FiHh8vCWIAMoz63.jpg) ([View Tweet](https://twitter.com/jayelmnop/status/1594817513556254725))
		- **Note**: Thread
	- 1Ô∏è‚É£ Improving Intrinsic Exploration with Language Abstractions
	  
	  Using language abstractions to guide exploration in RL, e.g. by self-designing a curriculum of increasingly difficult language goals
	  
	  https://t.co/hCzqqHWtx2
	  
	  Also see @ykilcher review: https://t.co/EsFtK2M70T
	  
	  (1/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817516039442433))
	- 2Ô∏è‚É£ Improving Policy Learning with Language Dynamics Distillation (led by @hllo_wrld) 
	  
	  Increasing RL sample efficiency by pretraining agents to model env dynamics from language-annotated demonstrations
	  
	  https://t.co/eC81X7ig8n
	  
	  (2/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817518027550720))
	- 3Ô∏è‚É£ STaR: Bootstrapping Reasoning with Reasoning (led by @ericzelikman, @Yuhu_ai_)
	  
	  Improving multistep reasoning in LMs by bootstrapping off of self-generated rationales
	  
	  Essentially doing RL in chain-of-thought rationale space!
	  
	  https://t.co/Hl2Njcn5Yw
	  
	  (3/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817520485433345))
	- 4Ô∏è‚É£ (bonus!) Active Learning Helps Pretrained Models Learn the Intended Task (led by @AlexTamkin)
	  
	  Revisiting classic active learning techniques in the context of modern foundation models and few-shot task ambiguity
	  
	  https://t.co/brHu6kRo1n 
	  
	  (4/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817522204909568))
	- To recap, I see LMs and RL converging from 2 directions:
	  
	  RL‚û°Ô∏è?‚¨ÖÔ∏èLMs
	  
	  Starting from RL: imbuing agents w/ language priors [1Ô∏è‚É£,2Ô∏è‚É£]
	  Starting from LMs: improving reasoning not from static corpora, but RL exploration & interaction [3Ô∏è‚É£]
	  
	  Excited for these paths to intertwine!
	  
	  (5/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817524100911104))
	- I'm on the job market! Mostly industry (+startups). Interested in both traditional RS positions *and* applied roles deploying products to users and improving from feedback. Please DM or reach out at NeurIPS!
	  
	  (Also reach out in general, happy to chat about anything)
	  
	  (6/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594817525400969235))
	- Thank you to my wonderful coauthors: @robertarail, @hllo_wrld, @MinqiJiang, @_rockt, @egrefen, @LukeZettlemoyer, @ericzelikman, @Yuhu_ai_, @AlexTamkin, Salil Deshpande, Dat Nguyen, and Noah Goodman!
	  
	  (7/7) ([View Tweet](https://twitter.com/jayelmnop/status/1594818677761019905))