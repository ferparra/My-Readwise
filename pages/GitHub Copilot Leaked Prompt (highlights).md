title:: GitHub Copilot Leaked Prompt (highlights)
author:: [[ycombinator.com]]
full-title:: "GitHub Copilot Leaked Prompt"
category:: #articles
url:: https://news.ycombinator.com/item?id=35924293

- Highlights first synced by [[Readwise]] [[May 15th, 2023]]
	- Delimiters wonâ€™t save you from prompt injection - [https://simonwillison.net/2023/May/11/delimiters-wont-save-y...](https://simonwillison.net/2023/May/11/delimiters-wont-save-you/) - talks about why telling a model to follow delimiters like ``` won't protect against prompt injection, despite that being mentioned as a solution in a recent OpenAI training series