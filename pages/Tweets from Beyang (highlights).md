title:: Tweets from Beyang (highlights)
author:: [[@beyang on Twitter]]
full-title:: "Tweets from Beyang"
category:: #tweets
url:: https://twitter.com/beyang

- Highlights first synced by [[Readwise]] [[May 15th, 2023]]
	- This is why LLM portability matters https://t.co/FwRs1BacBR. If you’re using Copilot, you have a 2-year old model with 2k tokens of context that doesn’t know anything past 2021. If you’re using Cody, you can use Claude, GPT-4, and the latest, greatest LLMs as they come online,… ([View Tweet](https://twitter.com/beyang/status/1656722846452940801))
	- If you'd like to play with @AnthropicAI's new 100k-token model using @LangChainAI, Cody offers a great way to learn new libraries and APIs.
	  
	  This illustrates another advantage Cody has over Copilot: freshness. Cody uses @sourcegraph to fetch context from current code. Its… 
	  
	  ![](https://pbs.twimg.com/media/Fv8SNCoagAIVC_k.jpg) ([View Tweet](https://twitter.com/beyang/status/1657064877855477765))