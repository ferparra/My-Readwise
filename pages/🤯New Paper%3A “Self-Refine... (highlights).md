title:: 🤯New Paper: “Self-Refine... (highlights)
author:: [[@peteskomoroch on Twitter]]
full-title:: "🤯New Paper: “Self-Refine..."
category:: #tweets
url:: https://twitter.com/peteskomoroch/status/1642721632144990210

- Highlights first synced by [[Readwise]] [[Apr 7th, 2023]]
	- 🤯New paper: “Self-Refine: Iterative Refinement with Self-Feedback” shows LLMs can improve themselves without humans.
	  
	  “SELF-REFINE is unique in that it operates within a single LLM, requiring neither additional training data nor reinforcement learning.” https://t.co/8Coo3T66kZ 
	  
	  ![](https://pbs.twimg.com/media/FswenaWakAEBoFs.jpg) 
	  
	  ![](https://pbs.twimg.com/media/FswenaTacAEqKbU.jpg) 
	  
	  ![](https://pbs.twimg.com/media/FswenaWacAAh1zw.jpg) ([View Tweet](https://twitter.com/peteskomoroch/status/1642721632144990210))
		- **Note**: Thread
	- I have a BS in math/physics, had a career in machine learning, and worked at one of the largest social networks during early hyper-growth. I never fully appreciated power laws until today. If we say something follows a power law, we mean “the bigger it gets, the faster it grows”. ([View Tweet](https://twitter.com/peteskomoroch/status/1642724339081707521))