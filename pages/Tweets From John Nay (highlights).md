title:: Tweets From John Nay (highlights)
author:: [[@johnjnay on Twitter]]
full-title:: "Tweets From John Nay"
category:: #tweets
url:: https://twitter.com/johnjnay

- Highlights first synced by [[Readwise]] [[Mar 28th, 2023]]
	- Scaling Expert LLMs
	  
	  -Cluster corpus into domains
	  -Train separate expert LLM on each cluster
	  -Combine in a sparse ensemble for inference
	  
	  -Outperforms dense baselines on multiple corpora &
	  tasks
	  -Specializing "experts" to meaningful clusters is key
	  
	  Paper: https://t.co/Oi6kPncis0 
	  
	  ![](https://pbs.twimg.com/media/FsMKHTqXgAEphw2.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1640167659697209347))
- New highlights added [[Mar 28th, 2023]] at 2:40 PM
	- LLMs Can Outperform Humans on Data Annotation
	  
	  -Compare 0-shot accuracy of ChatGPT vs crowd-workers on:
	  relevance
	  topic detection
	  stance detection
	  general frame detection
	  policy frame detection
	  
	  -ChatGPT better on 4/5 tasks
	  -20x cheaper than MTurk
	  
	  Paper: https://t.co/lcVMqbFBFu 
	  
	  ![](https://pbs.twimg.com/media/FsRSS5OXgAAqRC8.png) ([View Tweet](https://twitter.com/johnjnay/status/1640526916166774784))
- New highlights added [[Mar 29th, 2023]] at 5:26 PM
	- Planning Helps LLMs w/ Logical Reasoning
	  
	  -Incorporating explicit planning into inference enables more informed reasoning decisions by looking ahead to future effects
	  
	  -Performs competitively to GPT-3 on Q&A task despite only having ~1.5B parameters
	  
	  Paper https://t.co/wZuxooN04z 
	  
	  ![](https://pbs.twimg.com/media/FsWiUhfWAAIZYwA.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1640897259331100673))
- New highlights added [[Mar 31st, 2023]] at 11:28 AM
	- Language Models Can Predict Public Opinion
	  
	  -Adapt LMs to news data to emulate subpopulation opinions
	  -Eval w/ ground truth of opinions in surveys on COVID-19 & consumer confidence
	  -Predictive of human judgements & 
	  of who follows media more closely
	  
	  Paper https://t.co/DD1nNSkCA9 
	  
	  ![](https://pbs.twimg.com/media/FsdreO5XgAIhnPa.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1641400468667498502))
- New highlights added [[Apr 7th, 2023]] at 3:38 PM
	- LLMs Can Iteratively Self-Refine
	  
	  -LLM creates draft
	  -Provides its own feedback
	  -Iteratively refines
	  
	  On all 7 eval tasks
	  (review & code rewriting
	  toxicity removal
	  responses
	  acronyms
	  stories
	  etc.)
	  outputs are preferred by humans & by automated metrics
	  
	  https://t.co/qQl4VEAIsI 
	  
	  ![](https://pbs.twimg.com/media/FswLy55WwAI9v8G.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1642704826776559617))
	- A Framework For Applying Psychotherapy to LLMs
	  
	  -SafeguardGPT attempts to apply "psychotherapy" on LLMs
	  -4 types of Agents
	  Therapist
	  Chatbot
	  Critic
	  User
	  -Human moderator
	  -Simulates Chat / Therapy / Eval / Control phases to try to align to preferences
	  
	  https://t.co/roCF5JZbON 
	  
	  ![](https://pbs.twimg.com/media/Fs32NdlWAAEioEH.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1643241834158718979))
- New highlights added [[Apr 13th, 2023]] at 5:52 PM
	- Boosted Prompt Ensembles for LLMs
	  
	  -Construct a small set of few-shot prompts that comprise a "boosted prompt ensemble'"
	  -Examples chosen stepwise to be ones previous step's ensemble is uncertain of
	  -Outperforms single-prompt output-space ensembles
	  
	  https://t.co/6iezzNhbZF 
	  
	  ![](https://pbs.twimg.com/media/FtkA12eaQAAHTXJ.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1646349289386577920))
- New highlights added [[Apr 17th, 2023]] at 9:20 PM
	- Power-Seeking Can Be Probable For Trained AI Agents
	  
	  -Assuming trained AI agent learns a goal from set of goals consistent w/ training rewards:
	  -If agent faces a choice to 
	  shut down or avoid shutdown 
	  in a new situation, agent is likely to avoid shutdown
	  
	  https://t.co/mjMfxoLTqj 
	  
	  ![](https://pbs.twimg.com/media/Ft4IQNVWwAAOzLH.jpg) ([View Tweet](https://twitter.com/johnjnay/status/1647763679830581250))