title:: What Will Transformers Transform? (highlights)
author:: [[rodneybrooks.com]]
full-title:: "What Will Transformers Transform?"
category:: #articles
url:: https://rodneybrooks.com/what-will-transformers-transform/
document_note:: This document discusses the current state of Generative Pre-trained Transformer models (GPTs), such as GPT-3 and GPT-4, which have triggered much excitement and hype. It warns against overreliance on GPTs, noting that they have many limitations, such as their inability to reason and lack of a model of the world. It also cautions against using them in situations where they can be manipulated to produce harmful output, and emphasizes that they should be "boxed in" to prevent such misuse. Finally, it predicts that GPTs will be used to create both good and bad things that no one has yet imagined.
tags:: #[[GPT]] #[[LLMs]]

- Highlights first synced by [[Readwise]] [[Mar 24th, 2023]]
	- We [humans] are able to generalize from observing performance at one task to a guess at competence over a much bigger set of tasks. We understand intuitively how to generalize from the performance level of the person to their competence in related areas. ([View Highlight](https://read.readwise.io/read/01gw99xtcht6smtagsqtxextzb))
	- As noted above in 2.2, despite GPT-4â€™s capabilities, it maintains a tendency to make up facts, to double-down on incorrect information, and to perform tasks incorrectly. Further, it often exhibits these tendencies in ways that are more convincing and believable than earlier GPT models (e.g., due to authoritative tone or to being presented in the context of highly detailed information that is accurate), increasing the risk of overreliance. ([View Highlight](https://read.readwise.io/read/01gw99z0192tvxje32hd821sw3))
	- Always a person in the loop in successful AI Systems ([View Highlight](https://read.readwise.io/read/01gw99z8f3nqjtxzzyxv0egg4r))