title:: GPT-5 Is Not Needed to 1... (highlights)
author:: [[@alexalbert__ on Twitter]]
full-title:: "GPT-5 Is Not Needed to 1..."
category:: #tweets
url:: https://twitter.com/alexalbert__/status/1640767472147259394

- Highlights first synced by [[Readwise]] [[Mar 31st, 2023]]
	- gpt-5 is not needed to 100x the potential these models have
	  
	  we could stop all language model development today and we still haven’t scratched the surface of their capabilities 
	  
	  here are a few non-obvious ways language models can be improved without creating any new models: ([View Tweet](https://twitter.com/alexalbert__/status/1640767472147259394))
		- **Note**: Thread
	- running language models in parallel with each one focused on a sub-task, all orchestrated by a conductor language model
	  
	  picture something like a massive tree of GPT models working on answering a single complex prompt ([View Tweet](https://twitter.com/alexalbert__/status/1640767473090957312))
	- language models equipped with dynamic memory and the ability to reflect (e.g. Reflexion paper)
	  
	  https://t.co/K9MefZV960 ([View Tweet](https://twitter.com/alexalbert__/status/1640767474047287296))
	- language models running locally on your machine that treat more complex language models in the cloud like plug-ins
	  
	  https://t.co/cQyU8rsc7B ([View Tweet](https://twitter.com/alexalbert__/status/1640767475141992448))
	- using another language model for pre-processing your prompts to transform them into something that gives better responses 
	  
	  if you want a prompt that you can use to already do this, read the prompt tip section here:
	  https://t.co/FCgDwrkgIE ([View Tweet](https://twitter.com/alexalbert__/status/1640767476026982401))
	- giving language models access to tools and api’s
	  
	  chatgpt has done this with plug-ins, no longer can you say chatgpt is bad at math or doesn't have access to current info
	  
	  soon every api on the internet will be forced to have language model interaction documentation ([View Tweet](https://twitter.com/alexalbert__/status/1640767476995854339))
	- language models with long-term memories using embeddings and semantic search 
	  
	  language models will be able to access some short convo you had a month prior ([View Tweet](https://twitter.com/alexalbert__/status/1640767477910241280))
	- using pre-created chained-prompt sequences instead of just one single prompt 
	  
	  as api costs continue to decrease this will become more popular, the intermediate prompts will be hidden and only the output will be shown
	  
	  could imagine chatgpt integrating a "prompt marketplace" ([View Tweet](https://twitter.com/alexalbert__/status/1640767479000752128))
	- I haven't even touched on the vision capabilities possible in gpt-4 
	  
	  some obvious ones:
	  -multi-modal reasoning and action (e.g. MM-REACT paper)
	  -better image gen (imagine gpt-4 iterates on your Midjourney prompts) 
	  -few-shot prompting and learning through images/videos ([View Tweet](https://twitter.com/alexalbert__/status/1640767479852195841))
	- reply if you have other ideas about how language models could currently be improved without any new developments and I'll add them to the thread ([View Tweet](https://twitter.com/alexalbert__/status/1640767480741388288))