title:: An Interview With Nvidia CEO Jensen Huang About AI’s iPhone Moment (highlights)
author:: [[Stratechery by Ben Thompson]]
full-title:: "An Interview With Nvidia CEO Jensen Huang About AI’s iPhone Moment"
category:: #articles
url:: https://stratechery.com/2023/an-interview-with-nvidia-ceo-jensen-huang-about-ais-iphone-moment/
tags:: #[[ai]] #[[nvidia]]

- Highlights first synced by [[Readwise]] [[Mar 28th, 2023]]
	- A lot of people, they never directly engaged the work that we were doing. We were talking about it, but most of the executives that I knew, they see the GTC Keynotes, they’re really excited about them, but it doesn’t affect them directly. Not one executive that I know, not one, has not been awoken by ChatGPT, now they call me and say “Now I understand what you were talking about. All of those things you were talking about, I get it now.” When I was explaining the transformers, these large language models, it’s first learning the language of humans, but it’s going to learn the language of everything, everything that has structure. So what has structure? Well, it turns out the physical world has structure, that’s why we’re symmetric, that’s why when I see the front of Ben, I have a feeling about the back of Ben.
	  
	  **You had an extensive bit on physics a couple of GTCs ago I think that was trying to make this point, but now people get it.**
	  
	  **JH:** Yeah, and there’s a language to proteins, there’s a language to chemicals, and if we can understand the language and represent it in computer science, imagine the scale at which we can move, we can understand, and we can generate. We can understand proteins and the functions that are associated with them, and we can generate new proteins with new properties and functions. We can do that with generative AI now, now all of a sudden those words make sense and now they’re connecting and fired up and are now applying it to all of their fields of their own companies and see opportunity after opportunity for themselves to apply it. So I think the “AI Moment”, ChatGPT, was a very important deal, it kind of opened everybody’s mind. ([View Highlight](https://read.readwise.io/read/01gwe057yjwmyyxh2nnxf01kf5))
	- **Got it. What is the constraint on building more and meeting this demand? Is it just the ability to make chips? Is it data centers that can house them? Is it the customer base actually coming to the table and putting money down? What’s the limiting factor?**
	  
	  **JH:** Well, you’ve kind of identified quite a few of them. First of all, people think that a GPU is a chip, but it’s not. If you think about what our data center GPUs are, it’s eight chips with two-and-a-half DCA [*unclear*] packaging interconnected into NVLink with a thermal management system that is off the charts, delivering a few thousand amps at a few gigahertz. It is a very heavy computer, I think just lifting a Hopper out of the oven is probably something along the lines of 70 pounds with 35,000 individual components. So building that GPU is, even if you had the five nanometer wafers, you’re still missing a whole lot of components and then there’s the manufacturing part of it.
	  
	  Now that’s just a GPU. In order stand up one of these AI supercomputers, you got switches, you have all the NICs, you have all the cables, and then you still have data center space you got to stand up, the PDUs — all of it is critical path, none of it’s easy. These are the most advanced computers the world makes today, and we make them in volume and so we’re moving as fast as we can, everybody’s in a bit of a race and there’s a great deal of urgency to get there and so we recognize that and we’re working as hard as we can. ([View Highlight](https://read.readwise.io/read/01gwe0738mc7sy82myb0hrvw7n))
	- CUDA and Commoditization
	  
	  **That last bit I’m really interested in because I’m curious — do you think there’s going to be companies that really never get into CUDA because that just didn’t make sense for that ecosystem as it was, but now they’re all in on LLM. So it’s like they’re higher up, they want to build stuff on top of LLMs and you talk about all the startups that’s sprouted up in the post-ChatGPT moment. Is the explosion of innovation — is this going to be in a fundamentally different layer of the stack going forward, just further up on top and that’s something that you foresee going forward?**
	  
	  **JH:** It depends on what applications you perform. If you’re creating a generative AI-based video-based storytelling service and you’re generating video at very high quality, you’re going to want to work with us to accelerate the living daylights out of that. Because the processing of that is just really long and so we could add a lot of value. However, if you’re a spell checker, I’m pretty sure that I would recommend you to a whole bunch of services and there’s just no sense in proving that. So long as it’s already accelerated on GPU, and I’m pretty sure it’ll be accelerated on just about everybody’s cloud, I think it’s going to be pretty terrific. I would venture to say that 80% of the world should just go directly to the cloud, one of our partners, and we’ll work directly with our cloud service providers to make sure that the infrastructure and their services and their APIs are all as accelerated as possible, and that would be terrific. For some of them that can’t, for whatever reason, they’re welcome to work with us. ([View Highlight](https://read.readwise.io/read/01gwe09e2pnzzzh2x9522xpjws))
	- Centralized vs. Localized Compute
	  
	  **One other big question I have about AI generally is the question of centralized versus local. Obviously, centralized has huge advantages in terms of the compute-to-command and scalability. At the same time, there are costs attached to it and real controls that people may not always like. Meanwhile, we have seen models that run locally for Stable Diffusion in terms of image generation and then [these past few weeks](https://stratechery.com/2023/gpt-4-google-adds-ai-to-productivity-apps-local-language-models/) Meta’s LLaMA model for language. Do you think that we will see meaningful generative AI applications run locally? Number two, do you see much of a market opportunity for Nvidia there? Right now the best option is obviously an Nvidia gaming GPU, get a 4090. Should there be a consumer AI GPU?**
	  
	  **JH:** Inference will be the way software is operated in the future. Inference is simply a piece of software that was written by a computer instead of a piece of software that was written by a human and every computer will just run inference someday. Every computer will be a generative AI someday. Why look up an answer if you already know the answer? Every question that you ask me, if I have to go look it up or go find a bunch of friends and caucus and then come back and give you the answer, that takes a lot more energy than what’s already in my brain, and just call it 25 watts. I’m sitting here producing answers all day long —
	  
	  **Producing answers for the last hour, which I appreciate!**
	  
	  **JH:** Right, so this is completely generative AI. Generative AI is the most energy-conserving way to do computing, there’s no question about that. And of course the question is when can we do that on a large scale? Well, Ben, back in the old days, in order to run OpenGL, it started out in the data center in a Reality Engine, and then it was $100,000 – $150,000 workstation and now you’ve run OpenGL on a phone. The same exact thing is going to happen with inference. Today, large language models, the largest ones requires A100 HGX to run, so that’s a couple of hundred thousand dollars. But how long would it be before we can have smaller versions of that, and quite performant versions of that running on cell phones? No more than ten years. We’re going to run inferences literally everywhere of all different sizes. Distributed computing is very cost-effective, it’s not going to go away. However, in the future, you’ll do some inference on the phone, you’ll do some inference on your PC, but you’ll always have the backup, you’ll always be connected to a cloud model which is much more capable as a backup to the smaller version on the device and so I have a lot of confidence that today’s computing model is going to remain. ([View Highlight](https://read.readwise.io/read/01gwe0a13x6hrh2ynmhe8gs2zh))