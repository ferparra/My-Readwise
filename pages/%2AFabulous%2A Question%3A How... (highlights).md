title:: *Fabulous* Question: How... (highlights)
author:: [[@GaryMarcus on Twitter]]
full-title:: "*Fabulous* Question: How..."
category:: #tweets
url:: https://twitter.com/GaryMarcus/status/1595101001035698176

- Highlights first synced by [[Readwise]] [[Nov 23rd, 2022]]
	- *Fabulous* question: How come smart assistants have virtually no ability to converse, despite all the spectacular progress with large language models? 
	  
	  Thread (and substack essay), inspired by a reader question from @___merc___ 
	  
	  ![](https://pbs.twimg.com/media/FiLv568aYAAt6OW.jpg) ([View Tweet](https://twitter.com/GaryMarcus/status/1595101001035698176))
		- **Note**: Thread
	- 1. LLMs are inherently unreliable. If Alexa were to make frequent errors, people would stop using it. Amazon would rather you trust Alexa for timers and music than have a system with much broader scope that you stop using. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104103394574336))
	- 2. LLMs are unruly beasts; nobody knows how to make them refrain 100% of time from insulting users, giving bad advice, or goading them into bad things. Nobody knows how to solve this. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104161989025794))
	- 3. Amazon doesn't want to get sued. Any one of these scenarios of LLMs gone awry  (bad advice, insults, lies etc) could hurt the Amazon brand, open up litigation, etc.. It's just not worth the risk. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104226551947266))
	- 4. Alexa has to do stuff in the world, like turning on lights, opening shades,, If Alexa could converse freely, user expectations would go through the roof, & mostly be unmeetable. You could ask Alexa to wash dishes, but until robot division picks up speed, that ainâ€™t happening. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104606828527616))
	- 5. LLMs spit our words, not actions (and not API calls either). When an LLM produces a sentence, you can't directly use that sentence to control stuff, unless you build another system to parse the sentences into actions. Nobody knows how to do this reliably, either. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104676059709440))
	- Bottom line: From the outset Large Language Models like GPT-3 have great at generating surrealist prose, and they can beat a lot of benchmarks, but they are not (and may never be) great tech for reliably inferring user intent from what users say. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104738319953921))
	- Full version of this can be found at  https://t.co/OFidJ1B1t6
	  If you enjoyed this, please consider subscribing (free) for more analysis of where AI is and how we might eventually get to AGI. ([View Tweet](https://twitter.com/GaryMarcus/status/1595104999771889665))