title:: Capabilities of GPT-4 on Medical Challenge Problems (highlights)
author:: [[ycombinator.com]]
full-title:: "Capabilities of GPT-4 on Medical Challenge Problems"
category:: #articles
url:: https://news.ycombinator.com/item?id=35319778

- Highlights first synced by [[Readwise]] [[Mar 28th, 2023]]
	- Clinical pharmacist for 10 years here. Yea, base model is very good. Better than first year residents - but not necessarily experienced clinicians.
	  
	  Now - throw a punch of clinical guidelines in a vector database and give it context and it’s 10x better than me and any doctor outside their speciality or all the mid-levels. (I.E, it’s better than cardiologist doing infectious disease - but not cardiologists doing cardiology). This because there are very niche stuff as you specialize where it’s only like 5 doctors who see it in the whole world on a consistent basis (and they don’t blog!)
	  
	  I trained it on the IDSA guidelines (infectious disease) and put up a proof of concept on GalenAI.co - just as way to start talking to health systems and clinicians. it’s going to be very different world in medicine in a couple of years from now!! ([View Highlight](https://read.readwise.io/read/01gwg92f77zj9h2hve61az10ga))
	- LLMs like GPT4 operate on tokens, not characters, so they're operating with a severe handicap when playing those sorts of games -- they see a word like "robot" as a single token, not as a collection of letters, so they don't know that it starts with the letter R unless that fact appeared in its training material.
	  
	  Interestingly, they do better at rhyming games, because those are based on associations between tokens which are easier to infer from usage in poetry, or by reading rhyming dictionaries. ([View Highlight](https://read.readwise.io/read/01gwg91swgk0dk76p3vbns99p7))