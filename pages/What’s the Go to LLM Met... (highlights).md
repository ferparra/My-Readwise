title:: What’s the Go to LLM Met... (highlights)
author:: [[@GregKamradt on Twitter]]
full-title:: "What’s the Go to LLM Met..."
category:: #tweets
url:: https://twitter.com/GregKamradt/status/1653060004226924544

- Highlights first synced by [[Readwise]] [[May 5th, 2023]]
	- What’s the go to LLM method to summarize a whole book, say 450 page, fiction.
	  
	  I want to do it myself and not use a 3rd party tool.
	  
	  It feels like it is an embedding selection problem in disguise
	  
	  My current first reaction approach: cont. ([View Tweet](https://twitter.com/GregKamradt/status/1653060004226924544))
		- **Note**: Thread
	- Split the whole thing into largish chunks, get vectors, then cluster
	  
	  Pick a representative from each cluster (likely closest to the centroid) to get a wholistic, but diverse set of chunks about the book
	  
	  Then use a regular summary method
	  
	  Am I over thinking it? ([View Tweet](https://twitter.com/GregKamradt/status/1653060006701592576))