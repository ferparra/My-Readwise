title:: 148 Kenneth Stanley —  Set the Right Objectives (highlights)
author:: [[The Knowledge Project with Shane Parrish]]
full-title:: "\#148 Kenneth Stanley —  Set the Right Objectives"
category:: #podcasts
url:: https://share.snipd.com/episode/1c5999d3-e7b7-4563-b2c8-ff916be6894e

- Highlights first synced by [[Readwise]] [[Feb 28th, 2023]]
	- The Core Problem With Ambitious Objectives
	  
	  Key takeaways:
	  (* Setting ambitious objectives can be counterproductive, as it can lead to less progress., * It is important to be open to the unexpected and unplanned in order to achieve success.)
	  
	  Transcript:
	  Speaker 2
	  So the core problem with the ambitious objectives then is that in many cases trying harder won't help you achieve the outcomes you're seeking and sort of like a follow on to that. You can't be so tied to your vision of accomplishment that you're not open to the unexpected and unplanned.
	  
	  Speaker 1
	  Yeah. So it is true that like one of the principles in the book is that you can actually block your own ability to reach an objective by setting it, which is paradoxical. So grappling with that is, you know, hard and important and something that the book tries to discuss, like how to grapple with that. But yes, we're actually causing ourselves to achieve less in these ambitious cases by setting very ambitious objectives. And one of the things that we do when we set an ambitious objective conventionally is that we would also set some metrics up to measure progress towards that objective. And that's where I think things really get tripped up is these metrics or assessments. We love assessment in our culture. We have very big assessment culture. And the assessment is basically trying to give us a security blanket so we can feel like we're moving towards the objective and that we're actually making progress. And the problem is that a lot of the time, even if your score on a metric is going up in the short run, it doesn't mean it will all get all the way to the point that you want it to get. It's a fundamental problem. It's called deception. And it's a fundamental problem of all complex problems. And so the fact that we rely so much on these assessments in metrics is very deceiving and can ultimately cause us to invest a lot in a deceptive path, which is actually going to lead to a dead end. And that's why it can actually be, although it's counterintuitive, it can actually be bad for you to have a very strict objective that you're assessing movement towards.
	  
	  Speaker 2
	  Let's sort of make that tangible. One of the examples you give in the book around that is schools and improving student performance. And I'm thinking here that's both hard to argue with. And it also never seems to improve despite billions, if not trillions of dollars. And so progress sort of can't be packed into a single metric. But what should we do instead for something like that where we also need accountability on behalf of sort of politicians or decision makers who have some sort of skin in the game for their choices?
	  
	  Speaker 1
	  That word accountability always comes up. Is it sort of like why we feel like we have to have these metrics and assessments? And education's a great example of this. Because the education system does have an objective. And it's a little bit fuzzy. It's not usually stated explicitly, but I would characterize it as something like the objective of the education system is for everyone that's in the education system, all of the students to score perfectly on a bunch of assessment tests. That would be ideal if everybody was perfect, of course. We're never going to get quite to there. But that would be the ultimate perfect objective. What leads you to that outcome? We don't come close to that outcome right now. We have many people whose performance is way below what we want to see. So that's our problem. That's what the problem with the education system is. And so we're trying to solve it by being objective. So we say, okay, well, what we need then is we need some standardized tests. We're going to blanket the entire country basically with these standardized tests and other countries too do something similar. And then we have a universal measure or metric that can be used to decide whether progress is going well in local locations. If what's going on in your local school district is still being assessed with this kind of a global test that is used across the nation, then we can compare things and see if things are moving in the right direction in different locations. And the problem is that this is subject to this deceptive problem or what I call this objective paradox, which is that you can look like your metrics are going up a little bit from year to year. But that has nothing to do with necessarily getting to a point where everybody is scoring perfectly or even above the threshold that we would consider acceptable. And that's borne out by history. Like it never happens. We keep on trying to revive every decade or something like there's a whole new push to like, let's really do this seriously this time. And just the same thing over and over again, like we don't learn from this mistake. It's that the problem isn't that the assessment is somehow flawed. The problem is with assessment itself. It cannot make progress in certain kinds of extremely complex problems, which education is one of those simply by just laying out some assessment system and then trying to follow it towards this global objective, which is just incredibly complex to get to. But what comes into play then is what you said, which is this accountability issue. If you get a critique like what I just said at first, I mean, people make critiques obviously against standardized tests. And the response is usually like, okay, well, where's the accountability going to come from? This is the way to hold people responsible. And the problem is that it's not necessarily a dichotomy, the way it's being presented where like you either have accountability or you have no assessment at all. There is a possibility of having accountability with a different approach. But we need to have an approach that recognizes how you actually make innovative progress in an extremely complex problem, which is the book tries to get into in general how those kinds of discoveries are made. And really what happens in these kinds of problems is that because we don't know the stepping stones, like this is the key thing, the stepping stones that we need to traverse through in order to get to the outcome that we finally want, which in this case is like this universal high achievement, we don't actually know what we need to cross through. And what we can almost be sure is that one of those things that's not a stepping stone is everybody getting just a tiny bit better next year. Like that's not probably going to happen. And if it did happen, that not going to not probably going to lead to this kind of universal global high achievement. And so it's very deceptive. And so the stepping stones are likely things that are counterintuitive. And this is what where these metrics start to break down like that we use across all these institutions is that if the if the actual stepping stones that lead to where we want to go are counterintuitive, in other words, they're not what you would expect, then the metrics are useless, right? Because they won't detect those stepping stones because they don't look like what the metrics are trying to detect. And if you think about it, of course, they're going to be counterintuitive. It's like a rule, because the thing is, if the stepping stones are not counterintuitive, then it's not a hard problem. So we would have solved it already. Like that's basically what makes a problem hard is you don't know what the stepping stones are. If you do, then you don't have a problem. You don't even need to do the assessments. Just follow the stepping stones. And so because we don't know the stepping stones, what we need to do is we need to proliferate stepping stones, like stepping stone candidates, things that could lead to something interesting, but we don't know which one. ([Time 0:09:04](https://share.snipd.com/snip/d11c3fd7-df6c-4a38-849b-c105de3f604f))