title:: https://t.co/zAfTadJpZV... (highlights)
author:: [[@julesgm4 on Twitter]]
full-title:: "https://t.co/zAfTadJpZV..."
category:: #tweets
url:: https://twitter.com/julesgm4/status/1640384443142619137

- Highlights first synced by [[Readwise]] [[Mar 28th, 2023]]
	- https://t.co/zAfTadJpZV
	  I quite enjoyed this article. HuggingFace now has Peft, a library to easily use LoRA with HuggingFace Transformers models, making it pretty straightforward to train FLAN-T5-XXL & FLAN-UL2 on somewhat limited hardware, especially combined with HF Accelerate ([View Tweet](https://twitter.com/julesgm4/status/1640384443142619137))
		- **Note**: Thread
	- to fine-tune *
	  It is also what I would do if I had to fine-tune a model like Llama. This is very cool stuff. ([View Tweet](https://twitter.com/julesgm4/status/1640384650186031225))