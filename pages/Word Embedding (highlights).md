title:: Word Embedding (highlights)
author:: [[wikipedia.org]]
full-title:: "Word Embedding"
category:: #articles
url:: https://en.wikipedia.org/wiki/Word_embedding
tags:: #[[ai]]

- Highlights first synced by [[Readwise]] [[Jan 5th, 2023]]
	- In [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) (NLP), a **word embedding** is a representation of a word. The embedding is used in text analysis. Typically the representation is a real-valued vector that encodes the meaning of the word in such a way that words that are closer in the vector space are expected to be similar in meaning.[[1]](https://en.wikipedia.org/wiki/Word_embedding#cite_note-1) Word embeddings can be obtained using [language modeling](https://en.wikipedia.org/wiki/Language_model) and [feature learning](https://en.wikipedia.org/wiki/Feature_learning) techniques where words or phrases from the vocabulary are mapped to [vectors](https://en.wikipedia.org/wiki/Vector_(mathematics)) of [real numbers](https://en.wikipedia.org/wiki/Real_numbers). ([View Highlight](https://read.readwise.io/read/01gp088vzm3bexgn7cy73kwy22))