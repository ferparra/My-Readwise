title:: Do Large Language Models Learn World Models or Just Surface Statistics? (highlights)
author:: [[The Gradient]]
full-title:: "Do Large Language Models Learn World Models or Just Surface Statistics?"
category:: #articles
url:: https://thegradient.pub/othello/

tags:: #[[gpt]] #[[GPT]] #[[llms]] #[[LLMs]]

- Highlights first synced by [[Readwise]] [[Feb 16th, 2023]]
	- They are trained by playing a guess-the-next-word game with itself over and over again. Each time, the model looks at a partial sentence and guesses the following word. If it makes it correctly, it will update its parameters to reinforce its confidence; otherwise, it will learn from the error and give a better guess next time. ([View Highlight](https://read.readwise.io/read/01gs9q1hc2kjcnrrpcwx8hmm1y))
	- How do these models achieve this kind of performance? Do they merely memorize training data and reread it out loud, or are they picking up the rules of English grammar and the syntax of C language? Are they building something like an internal world modelâ€”an understandable model of the process producing the sequences? ([View Highlight](https://read.readwise.io/read/01gs9q2fxsn7mc8rn9hjsg6t7p))