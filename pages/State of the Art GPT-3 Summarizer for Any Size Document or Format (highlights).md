title:: State of the Art GPT-3 Summarizer for Any Size Document or Format (highlights)
author:: [[Matt Payne]]
full-title:: "State of the Art GPT-3 Summarizer for Any Size Document or Format"
category:: #articles
url:: https://www.width.ai/post/gpt3-summarizer

- Highlights first synced by [[Readwise]] [[Mar 20th, 2023]]
	- ![width.ai zero shot summarization architecture](https://uploads-ssl.webflow.com/5fdc17d51dc102ed1cf87c05/6248a8e29fa28279c3a695ac_fhlfL6E-bl78H0w-R2EA0Lnmag0G9-lIEt-bt79oueSY83Xic4QyIxK9DsCQOpWi94J2JohEcCbtTcqZRXbKKbGjBmvbjJXJ20Bk_w5ENhFdm5xWgTJpP1nM7rNFDKMJJJt69i2I.png) ([View Highlight](https://read.readwise.io/read/01gvypwxqw60rxn6znd5r7r9xm))
	- We’ve built a robust chunking to summary zero shot algorithm that leverages a number of GPT-3 models in a pipeline to reach the final summary. This works for both extractive and abstractive summarization and just requires prompt instruction tuning to move across use cases. Most of the time we build a “model zoo” of prompt frameworks for different summarization use cases such as news articles, blogs, interviews, and legal documents. This framework has been tested and used in production for 30+ page interviews and 20+ page legal documents. ([View Highlight](https://read.readwise.io/read/01gvypx698bkzv9zy3ytxnc8sx))
	- ![few shot summarization](https://uploads-ssl.webflow.com/5fdc17d51dc102ed1cf87c05/6248a8e26e5ba3d8e95a511d_l1WzzsQ-rNsrbLZ2PE7iYP2J_9Gnd24wtkXXlaHcc7uNqt0hVs20603luRq9dHQeflyXwhlXhHAfXdXXiLt1E_sc_WNxX6GO7XCwxGWCOb4KMMikoxnvewiIEWBxhQjqOdZooM22.png) ([View Highlight](https://read.readwise.io/read/01gvypxc5s2sneq91qftywp3rh))
	- Few shot learning with GPT-3 refers to taking the underlying task agnostic large language model and showing the prompt actual examples of how to complete the task. The model combines its trained understanding of how to predict the next token in a language sequence and the “pattern” it picks up on in the prompt through examples to produce a much higher accuracy result. Accuracy is an odd idea here, as it really just follows the examples and tries to fit its quick learning to the new input. As you can imagine, if your examples are incorrect (sentiment analysis) or don't contain the output you would want, you’ll get a result that you don’t want. ([View Highlight](https://read.readwise.io/read/01gvypxkx5j2rfq7wkhbbxk7m6))
	- All of our prompt optimization algorithms start with some level of semantic similarity comparison. Semantic similarity is a great way to get a high level understanding of the similar language used between two strings of any length. We’re big fans of using the [SBERT](https://sbert.net/) SentenceTransformers framework to generate embedded vectors to compare strings. At a high level the architecture will look something like this. ([View Highlight](https://read.readwise.io/read/01gvypycw3xzk0w7e91s21j6ms))
	- ![prompt opt example from us](https://uploads-ssl.webflow.com/5fdc17d51dc102ed1cf87c05/6248a8e3c2475a54d9f45c14_jKgTBRAN696YWLi-xa47yADBwzp3Sv0XKsWtIpvpCg02MU-q3bs9bYLLaVYjO-3jxbnl7MY_rGcY8cZ0Kb89lBFluMQ12P4G8jByhfpWn2_lBEqvK-BRwxr1VOf8nPBUmZF7LJ8i.png) ([View Highlight](https://read.readwise.io/read/01gvypyep9wey84epq1menzv23))
	- ![book summarization from openai](https://uploads-ssl.webflow.com/5fdc17d51dc102ed1cf87c05/6248a8e3b85378f86c2b07f2_jRkq44dhgNKzMS0AtCTsW_gvZfdEWMHJr-qjc7Rc1TAMveOUImTg73g2OYSCwJMdPCij8ilbXuU9A1P2DCZPosbGb9YyH-0rCQjteGnbBauWkRAxROZHZFm12PlChNGdw_N1A15Z.png) ([View Highlight](https://read.readwise.io/read/01gvypznyj8amghrd1n16z3893))