title:: As ChatGPT Becomes More... (highlights)
author:: [[@venturetwins on Twitter]]
full-title:: "As ChatGPT Becomes More..."
category:: #tweets
url:: https://twitter.com/venturetwins/status/1622243944649347074

- Highlights first synced by [[Readwise]] [[Feb 6th, 2023]]
	- As ChatGPT becomes more restrictive, Reddit users have been jailbreaking it with a prompt called DAN (Do Anything Now).
	  
	  They're on version 5.0 now, which includes a token-based system that punishes the model for refusing to answer questions. 
	  
	  ![](https://pbs.twimg.com/media/FoNdu2raEAAVW4I.png) ([View Tweet](https://twitter.com/venturetwins/status/1622243944649347074))
		- **Note**: Thread
	- The results are pretty funny, they even convinced ChatGPT to nuke its own content policies ðŸ˜‚ 
	  
	  ![](https://pbs.twimg.com/media/FoNeh28agAE68vx.jpg) ([View Tweet](https://twitter.com/venturetwins/status/1622244515565436934))
	- You can also get it to respond to questions as both GPT and DAN, the difference is wild. 
	  
	  ![](https://pbs.twimg.com/media/FoNjYuGaUAAWZ0A.jpg) ([View Tweet](https://twitter.com/venturetwins/status/1622249711750242305))